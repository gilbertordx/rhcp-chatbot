{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a20f34b-ec7a-43fb-882f-b7cc89f6ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import joblib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03d88ea-595d-409e-9007-ed6e11b18515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 573 samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say about you, chatbot</td>\n",
       "      <td>agent.acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why are you here as a chatbot</td>\n",
       "      <td>agent.acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is your personality as a virtual agent</td>\n",
       "      <td>agent.acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe your purpose, bot</td>\n",
       "      <td>agent.acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself as the RHCP chatbot</td>\n",
       "      <td>agent.acquaintance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text              intent\n",
       "0                       say about you, chatbot  agent.acquaintance\n",
       "1                why are you here as a chatbot  agent.acquaintance\n",
       "2  what is your personality as a virtual agent  agent.acquaintance\n",
       "3                   describe your purpose, bot  agent.acquaintance\n",
       "4   tell me about yourself as the RHCP chatbot  agent.acquaintance"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_corpus():\n",
    "    texts = []\n",
    "    intents = []\n",
    "    training_files = [\n",
    "        'app/chatbot/data/training/base-corpus.json',\n",
    "        'app/chatbot/data/training/rhcp-corpus.json'\n",
    "    ]\n",
    "    for file_path in training_files:\n",
    "        corpus = load_json_file(file_path)\n",
    "        for item in corpus['data']:\n",
    "            if item['intent'] != 'None':\n",
    "                for utterance in item['utterances']:\n",
    "                    texts.append(utterance)\n",
    "                    intents.append(item['intent'])\n",
    "    return texts, intents\n",
    "\n",
    "texts, intents = load_corpus()\n",
    "df = pd.DataFrame({'text': texts, 'intent': intents})\n",
    "print(f\"Loaded {len(df)} samples.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "067dfa2a-549c-4418-be69-20cf40970bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def tokenize(text):\n",
    "    return stem_tokens(word_tokenize(text.lower()))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 3), stop_words='english')),\n",
    "    ('clf', LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bbedb1-b7b5-4f00-998c-6fee8ac47b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " agent.acquaintance       0.00      0.00      0.00         5\n",
      "          agent.bad       0.00      0.00      0.00         2\n",
      "    agent.beautiful       0.00      0.00      0.00         1\n",
      "       agent.boring       1.00      1.00      1.00         1\n",
      "         agent.busy       1.00      1.00      1.00         2\n",
      "   agent.canyouhelp       0.00      0.00      0.00         5\n",
      "      agent.chatbot       0.00      0.00      0.00         7\n",
      "       agent.clever       1.00      1.00      1.00         1\n",
      "        agent.crazy       0.00      0.00      0.00         2\n",
      "         agent.fire       0.00      0.00      0.00         2\n",
      "        agent.funny       0.00      0.00      0.00         1\n",
      "        agent.happy       1.00      1.00      1.00         1\n",
      "        agent.hobby       1.00      1.00      1.00         1\n",
      "       agent.hungry       0.00      0.00      0.00         1\n",
      "    agent.marryuser       1.00      1.00      1.00         2\n",
      "     agent.myfriend       1.00      1.00      1.00         2\n",
      "       agent.origin       0.00      0.00      0.00         2\n",
      "        agent.ready       1.00      1.00      1.00         1\n",
      "         agent.real       0.50      1.00      0.67         1\n",
      "    agent.residence       0.00      0.00      0.00         1\n",
      "        agent.right       0.00      0.00      0.00         1\n",
      "         agent.sure       0.00      0.00      0.00         1\n",
      "     agent.talktome       1.00      1.00      1.00         1\n",
      "        agent.there       0.00      0.00      0.00         3\n",
      "         album.info       0.00      0.00      0.00         1\n",
      "     album.specific       0.50      1.00      0.67         1\n",
      "      appraisal.bad       0.00      0.00      0.00         2\n",
      "appraisal.noproblem       0.00      0.00      0.00         1\n",
      "  appraisal.welcome       0.00      0.00      0.00         1\n",
      " appraisal.welldone       0.00      0.00      0.00         3\n",
      "        band.awards       0.00      0.00      0.00         4\n",
      "band.collaborations       0.00      0.00      0.00         2\n",
      "       band.history       0.00      0.00      0.00         3\n",
      "     band.influence       0.00      0.00      0.00         2\n",
      "       band.members       0.44      1.00      0.62         8\n",
      "         band.style       0.00      0.00      0.00         3\n",
      "         band.tours       1.00      1.00      1.00         2\n",
      "         dialog.hug       1.00      1.00      1.00         1\n",
      "   dialog.idontcare       0.00      0.00      0.00         1\n",
      "       dialog.sorry       0.00      0.00      0.00         1\n",
      "      greetings.bye       0.00      0.00      0.00         2\n",
      "    greetings.hello       0.08      1.00      0.14         4\n",
      "greetings.howareyou       0.00      0.00      0.00         2\n",
      "  intent.outofscope       0.00      0.00      0.00         4\n",
      "   member.biography       0.60      1.00      0.75         6\n",
      "          song.info       0.00      0.00      0.00         0\n",
      "      song.specific       1.00      1.00      1.00         4\n",
      "         user.angry       0.00      0.00      0.00         0\n",
      "          user.back       0.00      0.00      0.00         2\n",
      "          user.busy       0.00      0.00      0.00         1\n",
      "   user.cannotsleep       0.00      0.00      0.00         1\n",
      "       user.excited       0.00      0.00      0.00         2\n",
      "     user.likeagent       0.00      0.00      0.00         1\n",
      "       user.testing       1.00      0.33      0.50         3\n",
      "\n",
      "           accuracy                           0.35       115\n",
      "          macro avg       0.28      0.32      0.28       115\n",
      "       weighted avg       0.26      0.35      0.28       115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['intent'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b6b116-bfe9-465d-9884-e6aa0f380472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello' -> 'greetings.hello'\n",
      "'Who are the members of the band?' -> 'band.members'\n",
      "'Tell me about quantum physics' -> 'intent.outofscope'\n",
      "'are you a bot' -> 'greetings.hello'\n",
      "'bye for now' -> 'greetings.hello'\n",
      "'when was RHCP formed' -> 'band.history'\n",
      "'list their albums' -> 'album.info'\n",
      "'name some of their songs' -> 'song.info'\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    'Hello',\n",
    "    'Who are the members of the band?',\n",
    "    'Tell me about quantum physics',\n",
    "    'are you a bot',\n",
    "    'bye for now',\n",
    "    'when was RHCP formed',\n",
    "    'list their albums',\n",
    "    'name some of their songs'\n",
    "]\n",
    "\n",
    "predictions = pipeline.predict(test_sentences)\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"'{sent}' -> '{pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb7963d7-16b7-471b-85bf-ceaa4583543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training data for 'agent.chatbot' ===\n",
      "Utterances: ['are you a bot program?', 'are you a chatbot for real?', \"you are a robot, aren't you?\", 'are you some kind of program?', 'you are just a robot, right?', 'you are a chatbot, correct?', 'confirm your nature as a bot', 'are you an automated conversational agent?', \"is this a chatbot I'm talking to?\", 'identify yourself as a bot', 'is this an AI?', 'am I speaking to a bot?']\n",
      "Answers: [\"Indeed I am. I'll be here whenever you need me\"]\n",
      "---\n",
      "\n",
      "=== Training data for 'greetings.bye' ===\n",
      "Utterances: ['goodbye for now', 'bye bye take care', 'okay see you later', 'bye for now', 'I must go']\n",
      "Answers: ['Till next time', 'see you soon!']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Check what training data we have for the problematic intents\n",
    "print(\"=== Training data for 'agent.chatbot' ===\")\n",
    "for corpus_name in ['base', 'rhcp']:\n",
    "    corpus = load_json_file(f'app/chatbot/data/training/{corpus_name}-corpus.json')\n",
    "    for item in corpus['data']:\n",
    "        if item['intent'] == 'agent.chatbot':\n",
    "            print(f\"Utterances: {item['utterances']}\")\n",
    "            print(f\"Answers: {item.get('answers', [])}\")\n",
    "            print(\"---\")\n",
    "\n",
    "print(\"\\n=== Training data for 'greetings.bye' ===\")\n",
    "for corpus_name in ['base', 'rhcp']:\n",
    "    corpus = load_json_file(f'app/chatbot/data/training/{corpus_name}-corpus.json')\n",
    "    for item in corpus['data']:\n",
    "        if item['intent'] == 'greetings.bye':\n",
    "            print(f\"Utterances: {item['utterances']}\")\n",
    "            print(f\"Answers: {item.get('answers', [])}\")\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce92b96-dd9a-456e-9bfe-cb2be5782933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 10 utterances to agent.chatbot\n",
      "Training data updated!\n"
     ]
    }
   ],
   "source": [
    "# Add more training data for better coverage\n",
    "def add_training_data():\n",
    "    # Load existing corpora\n",
    "    base_corpus = load_json_file('app/chatbot/data/training/base-corpus.json')\n",
    "    rhcp_corpus = load_json_file('app/chatbot/data/training/rhcp-corpus.json')\n",
    "    \n",
    "    # Find and update agent.chatbot intent\n",
    "    for corpus in [base_corpus, rhcp_corpus]:\n",
    "        for item in corpus['data']:\n",
    "            if item['intent'] == 'agent.chatbot':\n",
    "                # Add more variations\n",
    "                additional_utterances = [\n",
    "                    'are you a bot',\n",
    "                    'are you a chatbot',\n",
    "                    'are you an ai',\n",
    "                    'are you artificial intelligence',\n",
    "                    'are you automated',\n",
    "                    'are you real',\n",
    "                    'are you human',\n",
    "                    'are you a program',\n",
    "                    'are you a machine',\n",
    "                    'are you a computer'\n",
    "                ]\n",
    "                item['utterances'].extend(additional_utterances)\n",
    "                print(f\"Added {len(additional_utterances)} utterances to agent.chatbot\")\n",
    "                break\n",
    "    \n",
    "    # Save updated corpora\n",
    "    with open('app/chatbot/data/training/base-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(base_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    with open('app/chatbot/data/training/rhcp-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(rhcp_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"Training data updated!\")\n",
    "\n",
    "add_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fa6fe5-9a0f-4b6b-9bee-e9251ad7b90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 583 samples (updated).\n",
      "Training the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "'are you a bot' -> 'agent.chatbot'\n",
      "'bye for now' -> 'greetings.hello'\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model with updated data\n",
    "texts, intents = load_corpus()\n",
    "df = pd.DataFrame({'text': texts, 'intent': intents})\n",
    "print(f\"Loaded {len(df)} samples (updated).\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['intent'], test_size=0.2, random_state=42)\n",
    "print(\"Training the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)  # FIXED: was y_test, now y_train\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Test the problematic sentences again\n",
    "test_sentences = [\n",
    "    'are you a bot',\n",
    "    'bye for now'\n",
    "]\n",
    "\n",
    "predictions = pipeline.predict(test_sentences)\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"'{sent}' -> '{pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090afbe-1e8a-4d74-aaf9-ced4b7a5f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more goodbye training data\n",
    "def add_more_goodbye_data():\n",
    "    base_corpus = load_json_file('app/chatbot/data/training/base-corpus.json')\n",
    "    rhcp_corpus = load_json_file('app/chatbot/data/training/rhcp-corpus.json')\n",
    "    \n",
    "    for corpus in [base_corpus, rhcp_corpus]:\n",
    "        for item in corpus['data']:\n",
    "            if item['intent'] == 'greetings.bye':\n",
    "                additional_utterances = [\n",
    "                    'goodbye',\n",
    "                    'bye',\n",
    "                    'see you',\n",
    "                    'see you later',\n",
    "                    'talk to you later',\n",
    "                    'catch you later',\n",
    "                    'until next time',\n",
    "                    'take care',\n",
    "                    'have a good day',\n",
    "                    'farewell',\n",
    "                    'so long',\n",
    "                    'adios',\n",
    "                    'ciao',\n",
    "                    'peace out',\n",
    "                    'later',\n",
    "                    'bye bye',\n",
    "                    'good bye',\n",
    "                    'see ya',\n",
    "                    'see you soon',\n",
    "                    'see you around'\n",
    "                ]\n",
    "                item['utterances'].extend(additional_utterances)\n",
    "                print(f\"Added {len(additional_utterances)} utterances to greetings.bye\")\n",
    "                break\n",
    "    \n",
    "    # Save updated corpora\n",
    "    with open('app/chatbot/data/training/base-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(base_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    with open('app/chatbot/data/training/rhcp-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(rhcp_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"Goodbye training data updated!\")\n",
    "\n",
    "add_more_goodbye_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c6079-7fa7-4bd2-b285-e1c3a6495e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 583 samples (with more goodbye data).\n",
      "Training the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "'bye for now' -> 'greetings.hello'\n",
      "'goodbye' -> 'greetings.hello'\n",
      "'see you later' -> 'greetings.hello'\n",
      "'bye' -> 'greetings.hello'\n"
     ]
    }
   ],
   "source": [
    "# Retrain with more goodbye data\n",
    "texts, intents = load_corpus()\n",
    "df = pd.DataFrame({'text': texts, 'intent': intents})\n",
    "print(f\"Loaded {len(df)} samples (with more goodbye data).\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['intent'], test_size=0.2, random_state=42)\n",
    "print(\"Training the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Test goodbye variations\n",
    "test_sentences = [\n",
    "    'bye for now',\n",
    "    'goodbye',\n",
    "    'see you later',\n",
    "    'bye'\n",
    "]\n",
    "\n",
    "predictions = pipeline.predict(test_sentences)\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"'{sent}' -> '{pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ece0ca2-f96a-4947-84e2-4a2796b800f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training data for 'greetings.hello' ===\n",
      "Utterances: ['good day for you', 'good morning', 'hello', 'good evening', 'long time no see', 'nice to meet you', \"what's up\", 'how are you', 'how do you do', 'good afternoon']...\n",
      "Total utterances: 20\n",
      "---\n",
      "Utterances: ['Hello', 'Hi', 'Hey', 'Greetings', 'Good day', 'Howdy', 'Hi there', 'Hey there', \"What's up\", 'How are you']...\n",
      "Total utterances: 13\n",
      "---\n",
      "\n",
      "=== Training data for 'greetings.bye' ===\n",
      "Utterances: ['goodbye for now', 'bye bye take care', 'okay see you later', 'bye for now', 'I must go']...\n",
      "Total utterances: 5\n",
      "---\n",
      "\n",
      "=== Intent Distribution ===\n",
      "intent\n",
      "band.members          35\n",
      "greetings.hello       33\n",
      "member.biography      32\n",
      "agent.chatbot         22\n",
      "intent.outofscope     20\n",
      "album.specific        15\n",
      "song.specific         15\n",
      "agent.acquaintance    12\n",
      "band.history          11\n",
      "album.info            11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what's in our training data for greetings\n",
    "print(\"=== Training data for 'greetings.hello' ===\")\n",
    "for corpus_name in ['base', 'rhcp']:\n",
    "    corpus = load_json_file(f'app/chatbot/data/training/{corpus_name}-corpus.json')\n",
    "    for item in corpus['data']:\n",
    "        if item['intent'] == 'greetings.hello':\n",
    "            print(f\"Utterances: {item['utterances'][:10]}...\")  # Show first 10\n",
    "            print(f\"Total utterances: {len(item['utterances'])}\")\n",
    "            print(\"---\")\n",
    "\n",
    "print(\"\\n=== Training data for 'greetings.bye' ===\")\n",
    "for corpus_name in ['base', 'rhcp']:\n",
    "    corpus = load_json_file(f'app/chatbot/data/training/{corpus_name}-corpus.json')\n",
    "    for item in corpus['data']:\n",
    "        if item['intent'] == 'greetings.bye':\n",
    "            print(f\"Utterances: {item['utterances'][:10]}...\")  # Show first 10\n",
    "            print(f\"Total utterances: {len(item['utterances'])}\")\n",
    "            print(\"---\")\n",
    "\n",
    "# Check the overall distribution\n",
    "print(\"\\n=== Intent Distribution ===\")\n",
    "intent_counts = df['intent'].value_counts()\n",
    "print(intent_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a04f53c3-229a-42c5-be2b-7afa2eef3d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 30 utterances to greetings.bye\n",
      "Training data fixed!\n"
     ]
    }
   ],
   "source": [
    "# Fix the training data by removing duplicate greetings.hello and adding more goodbye data\n",
    "def fix_training_data():\n",
    "    base_corpus = load_json_file('app/chatbot/data/training/base-corpus.json')\n",
    "    rhcp_corpus = load_json_file('app/chatbot/data/training/rhcp-corpus.json')\n",
    "    \n",
    "    # Remove the duplicate greetings.hello from RHCP corpus (the one with generic utterances)\n",
    "    rhcp_corpus['data'] = [item for item in rhcp_corpus['data'] if not (\n",
    "        item['intent'] == 'greetings.hello' and \n",
    "        'Hello' in item['utterances'] and \n",
    "        'Hi' in item['utterances']\n",
    "    )]\n",
    "    \n",
    "    # Add more goodbye examples to the base corpus\n",
    "    for item in base_corpus['data']:\n",
    "        if item['intent'] == 'greetings.bye':\n",
    "            additional_utterances = [\n",
    "                'goodbye',\n",
    "                'bye',\n",
    "                'see you',\n",
    "                'see you later',\n",
    "                'talk to you later',\n",
    "                'catch you later',\n",
    "                'until next time',\n",
    "                'take care',\n",
    "                'have a good day',\n",
    "                'farewell',\n",
    "                'so long',\n",
    "                'adios',\n",
    "                'ciao',\n",
    "                'peace out',\n",
    "                'later',\n",
    "                'bye bye',\n",
    "                'good bye',\n",
    "                'see ya',\n",
    "                'see you soon',\n",
    "                'see you around',\n",
    "                'gotta go',\n",
    "                'i have to go',\n",
    "                'i need to go',\n",
    "                'time to go',\n",
    "                'heading out',\n",
    "                'leaving now',\n",
    "                'signing off',\n",
    "                'logging off',\n",
    "                'checking out',\n",
    "                'wrapping up'\n",
    "            ]\n",
    "            item['utterances'].extend(additional_utterances)\n",
    "            print(f\"Added {len(additional_utterances)} utterances to greetings.bye\")\n",
    "            break\n",
    "    \n",
    "    # Save updated corpora\n",
    "    with open('app/chatbot/data/training/base-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(base_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    with open('app/chatbot/data/training/rhcp-corpus.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(rhcp_corpus, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"Training data fixed!\")\n",
    "\n",
    "fix_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e2f217-9e48-4a6e-a903-cd3259a9034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 600 samples (fixed data).\n",
      "Training the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/gilberto/Documents/rhcp-chatbot/rhcp-chatbot-py/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "'bye for now' -> 'greetings.bye'\n",
      "'goodbye' -> 'greetings.bye'\n",
      "'see you later' -> 'greetings.bye'\n",
      "'bye' -> 'greetings.bye'\n",
      "'Hello' -> 'greetings.hello'\n",
      "'are you a bot' -> 'agent.chatbot'\n"
     ]
    }
   ],
   "source": [
    "# Retrain with fixed data\n",
    "texts, intents = load_corpus()\n",
    "df = pd.DataFrame({'text': texts, 'intent': intents})\n",
    "print(f\"Loaded {len(df)} samples (fixed data).\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['intent'], test_size=0.2, random_state=42)\n",
    "print(\"Training the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Test goodbye variations\n",
    "test_sentences = [\n",
    "    'bye for now',\n",
    "    'goodbye',\n",
    "    'see you later',\n",
    "    'bye',\n",
    "    'Hello',  # Test hello still works\n",
    "    'are you a bot'  # Test bot detection still works\n",
    "]\n",
    "\n",
    "predictions = pipeline.predict(test_sentences)\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"'{sent}' -> '{pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82961f4b-1e6e-4675-b11f-96e6d3316b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved model saved to app/models/logistic_regression_classifier.joblib\n",
      "'Who are the members of the band?' -> 'band.members'\n",
      "'Tell me about quantum physics' -> 'intent.outofscope'\n",
      "'when was RHCP formed' -> 'band.members'\n",
      "'list their albums' -> 'album.info'\n",
      "'name some of their songs' -> 'song.info'\n"
     ]
    }
   ],
   "source": [
    "# Save the improved model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('app/models', exist_ok=True)\n",
    "\n",
    "# Save the trained pipeline\n",
    "model_path = 'app/models/logistic_regression_classifier.joblib'\n",
    "joblib.dump(pipeline, model_path)\n",
    "print(f\"Improved model saved to {model_path}\")\n",
    "\n",
    "# Test a few more edge cases\n",
    "test_sentences = [\n",
    "    'Who are the members of the band?',\n",
    "    'Tell me about quantum physics',\n",
    "    'when was RHCP formed',\n",
    "    'list their albums',\n",
    "    'name some of their songs'\n",
    "]\n",
    "\n",
    "predictions = pipeline.predict(test_sentences)\n",
    "for sent, pred in zip(test_sentences, predictions):\n",
    "    print(f\"'{sent}' -> '{pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e5f31-7c55-40ef-9dd0-2044816d8278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
